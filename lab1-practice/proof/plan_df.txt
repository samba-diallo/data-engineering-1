2025-10-23 00:29:47.848974

AdaptiveSparkPlan isFinalPlan=false
+- TakeOrderedAndProject(limit=10, orderBy=[count#1446L DESC NULLS LAST,token#1445 ASC NULLS FIRST], output=[token#1445,count#1446L])
   +- HashAggregate(keys=[token#1445], functions=[count(1)], output=[token#1445, count#1446L])
      +- Exchange hashpartitioning(token#1445, 200), ENSURE_REQUIREMENTS, [plan_id=1021]
         +- HashAggregate(keys=[token#1445], functions=[partial_count(1)], output=[token#1445, count#1512L])
            +- Filter NOT (token#1445 = )
               +- Generate explode(split(lower(text#1052), \s+, -1)), false, [token#1445]
                  +- InMemoryTableScan [text#1052]
                        +- InMemoryRelation [id#1049, category#1050, value#1051, text#1052], StorageLevel(disk, memory, deserialized, 1 replicas)
                              +- Union
                                 :- FileScan csv [id#1049,category#1050,value#1051,text#1052] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/sable/Documents/data engineering1/lab1-practice/data/lab1_d..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<id:int,category:string,value:double,text:string>
                                 +- FileScan csv [id#1070,category#1071,value#1072,text#1073] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/sable/Documents/data engineering1/lab1-practice/data/lab1_d..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<id:int,category:string,value:double,text:string>
